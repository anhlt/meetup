# VJAI Meetup #18
:clock3: Thời gian: 14h~18h Chủ nhật - 02/12/2019 (mở cửa đón khách 13h40 ~ 13h55)

:point_right: Form đăng ký tham dự: https://forms.gle/DRiZg5bVyJKtQZuo8
(Hạn cuối đăng ký là 23:59 thứ 3 ngày 21/5/2019)

Sau buổi meetup với chủ đề ứng dụng AI trong y tế và giao lưu cùng VinAI, VJAI meetup trong tháng 5 sẽ đến với 2 chủ đề liên quan đến Deep Learning: 1 chủ đề về kỹ thuật quan trọng trong việc huấn luyện mô hình và 1 chủ đề về ứng dụng Deep Learning trong edge computing.

* Thời gian: 14h~18h Chủ nhật - 26/5/2018 (mở cửa đón khách 13h40 ~ 13h55)
* Địa điểm: Microsoft Japan office tầng 30 <br>
108-0075 東京都港区港南 2-16-3 品川グランドセントラルタワー <br>
https://www.microsoft.com/ja-jp/mscorp/branch/sgt.aspx

Hướng dẫn: từ ga JR Shinagawa cửa Kounan (港南口) đi theo skywalker là đến chỗ reception (tầng 2). Tại đây bạn sẽ lấy vé vào và lên tầng 30.

Chú ý: do yêu cầu an ninh toà nhà, đề nghị các bạn điền thông tin theo form dưới đây. Hạn cuối đăng ký là **23:59 thứ 3 - 21/5/2019**.

https://forms.gle/DRiZg5bVyJKtQZuo8

Ai không kịp đăng ký trước thời hạn trên sẽ không được vào toà nhà nên ngoài ấn Going thì các bạn **nhớ điền vào form** trên nhé.

Lần này ban tổ chức đã sắp xếp phòng rộng hơn nhưng cũng chỉ chứa được 50 người nên nếu số người đăng ký nhiều hơn, ban tổ chức sẽ áp dụng hình thức Lottery (như đã thông báo trên facebook group). Thêm nữa là việc vào toà nhà không dễ dàng nên các bạn tính toán thời gian cẩn thận để đến đúng giờ nhé.

Hẹn gặp lại cả nhà vào buổi sắp tới!

Nội dung chương trình:

---
- speaker: Tho Phan - VJAI
- title:  From Seq2seq with Attention to Abstractive Text Summarization
- abstract: Abstractive text summarization is nowadays one of the most important research topics in NLP. However, getting a deep understanding of what it is and also how it works requires a series of base pieces of knowledge that build on top of each other. This is the reason why this presentation will give audiences an overview of sequence-to-sequence with the acceleration of various versions of attention over the past few years. In addition, natural language generation (NLG) with the focusing on decoder techniques and its relevant problems will be reviewed, as a supportive factor to the light of the success of automatic summarization. Finally, the abstractive text summarization will be represented with potential approaches to tackle some hot issues in some latest research papers.
- Ref:
1. Neural Abstractive Text Summarization with Sequence-to-Sequence Models, https://arxiv.org/abs/1812.02303
2. Text Summarization with Pretrained Encoders, EMNLP-IJCNLP 2019, https://www.aclweb.org/anthology/D19-1387.pdf
3. Unified Language Model Pre-training for Natural Language Understanding and Generation, NeurIPS 2019, http://papers.nips.cc/paper/9464-unified-language-model-pre-training-for-natural-language-understanding-and-generation.pdf
4. Get To The Point: Summarization with Pointer-Generator Networks, ACL 2017, https://arxiv.org/pdf/1704.04368v2.pdf
5. Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model, ACL 2019, https://arxiv.org/abs/1906.01749
and others.
---
Title: Introduction to Survival Analysis
- Speaker: Phan Hoang Phuong
- Title: Starting with a question of how to predict duration of time until a death event occurs in clinical medical researches, survival analysis was developed as a branch of statistics to solve this question. Furthermore, survival analysis has been expanded to economics, engineering, and sociology. I would like to introduce this topic to you from Kaplan Meier model in 1958, to Cox model in 1972, and random forest, SVM recently. We will see how survival analysis was developed from a question of when or a time point of an event, to probability accumulation function or a death rate through out a life time, and further a death rate when multiple causes are taken into account.
- References:
1. Ishwaran H, Kogalur UB, Blackstone EH and Lauer MS (2008). "Random survival forests." The Annals of Applied Statistics, 2(3), 841-860
2. Graf E. et al. Assessment and comparison of prognostic classification schemes for survival data. Stat Med. 1999 Sep 15-30;18(17-18):2529-45.
3. https://kogalur.github.io/randomForestSRC/theory.html
4. Pölsterl, Sebastian, et al. "Fast training of support vector machines for survival analysis." Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Cham, 2015.
5. Pölsterl, Sebastian, et al. "An Efficient Training Algorithm for Kernel Survival Support Vector Machines." arXiv preprint
arXiv:1611.07054 (2016).
